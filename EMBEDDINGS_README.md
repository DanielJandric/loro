# File Embeddings System

Syst√®me complet pour cr√©er des embeddings de vos fichiers avec OCR Azure et stockage dans Supabase.

## üìã Table des mati√®res

- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Architecture](#architecture)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [API](#api)
- [Exemples](#exemples)

## ‚ú® Fonctionnalit√©s

- **OCR Azure** : Extraction de texte depuis PDFs et images
- **Embeddings OpenAI** : G√©n√©ration d'embeddings vectoriels (ada-002)
- **Stockage Supabase** : Base de donn√©es vectorielle avec pgvector
- **Recherche s√©mantique** : Recherche par similarit√© vectorielle
- **Chunking intelligent** : D√©coupage automatique des fichiers volumineux
- **Traitement batch** : Traitement de r√©pertoires entiers

## üèóÔ∏è Architecture

```
src/lib/
‚îú‚îÄ‚îÄ azure-ocr.ts                    # Service OCR Azure
‚îú‚îÄ‚îÄ embeddings.ts                   # Service g√©n√©ration embeddings
‚îú‚îÄ‚îÄ supabase-embeddings.ts          # Service stockage Supabase
‚îî‚îÄ‚îÄ file-embeddings-processor.ts    # Orchestrateur principal

scripts/
‚îú‚îÄ‚îÄ process-embeddings.ts           # Script de traitement batch
‚îî‚îÄ‚îÄ search-embeddings.ts            # Script de recherche

supabase/
‚îî‚îÄ‚îÄ schema.sql                      # Sch√©ma de la base de donn√©es
```

## ‚öôÔ∏è Configuration

### 1. Configuration Supabase

1. Cr√©ez un projet sur [Supabase](https://supabase.com)
2. Ex√©cutez le sch√©ma SQL :

```bash
# Dans le SQL Editor de Supabase, ex√©cutez le contenu de :
cat supabase/schema.sql
```

Cela va :
- Activer l'extension `pgvector`
- Cr√©er la table `file_embeddings`
- Cr√©er les index pour la recherche vectorielle
- Cr√©er la fonction `match_file_embeddings`

3. R√©cup√©rez vos cl√©s API depuis Settings > API

### 2. Configuration Azure

1. Cr√©ez une ressource Form Recognizer sur [Azure Portal](https://portal.azure.com)
2. R√©cup√©rez :
   - Endpoint : `https://your-resource.cognitiveservices.azure.com/`
   - Key : depuis "Keys and Endpoint"

### 3. Configuration OpenAI

1. Cr√©ez une cl√© API sur [OpenAI Platform](https://platform.openai.com)
2. R√©cup√©rez votre cl√© API

### 4. Variables d'environnement

Cr√©ez un fichier `.env` √† la racine du projet :

```bash
# Copiez le template
cp .env.example .env

# √âditez .env avec vos cl√©s
```

Remplissez avec vos cl√©s :

```env
# Supabase
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_ANON_KEY=eyJhbGc...
SUPABASE_SERVICE_ROLE_KEY=eyJhbGc...

# Azure Form Recognizer
AZURE_FORM_RECOGNIZER_ENDPOINT=https://xxxxx.cognitiveservices.azure.com/
AZURE_FORM_RECOGNIZER_KEY=xxxxx

# OpenAI
OPENAI_API_KEY=sk-xxxxx
```

## üöÄ Utilisation

### Traitement de fichiers

```bash
# Traiter un seul fichier
npm run embeddings:process -- public/data.csv

# Traiter un r√©pertoire entier
npm run embeddings:process -- public

# Traiter avec chunking (fichiers volumineux)
npm run embeddings:process -- public --chunk

# Ignorer les fichiers d√©j√† trait√©s
npm run embeddings:process -- . --skip-existing

# Options combin√©es
npm run embeddings:process -- documents --chunk --skip-existing --chunk-size=3000
```

### Options disponibles

- `--chunk` : D√©couper les fichiers volumineux en chunks
- `--skip-existing` : Ignorer les fichiers d√©j√† dans la base
- `--chunk-size=N` : Taille des chunks (d√©faut: 2000 caract√®res)

### Recherche s√©mantique

```bash
# Recherche simple
npm run embeddings:search -- "lottery statistics"

# Recherche avec threshold personnalis√©
npm run embeddings:search -- "probability analysis" --threshold=0.8

# Limiter le nombre de r√©sultats
npm run embeddings:search -- "data analysis" --threshold=0.7 --limit=5
```

## üìö API

### FileEmbeddingsProcessor

Service principal orchestrant tout le processus.

```typescript
import { FileEmbeddingsProcessor } from '@/lib/file-embeddings-processor';

const processor = new FileEmbeddingsProcessor();

// Traiter un fichier
await processor.processFile('/path/to/file.pdf', {
  skipExisting: true,
  chunkLargeFiles: true,
  verbose: true,
});

// Traiter un r√©pertoire
await processor.processDirectory('/path/to/dir', {
  skipExisting: true,
  chunkLargeFiles: true,
});

// Rechercher
const results = await processor.search(
  'your query',
  0.7,  // threshold
  10    // limit
);
```

### AzureOCRService

Service d'extraction de texte avec Azure.

```typescript
import { AzureOCRService } from '@/lib/azure-ocr';

const ocr = new AzureOCRService();

// Extraction simple
const text = await ocr.extractText('/path/to/document.pdf');

// Extraction d√©taill√©e
const details = await ocr.extractDetailedText('/path/to/document.pdf');
console.log(details.pages); // Nombre de pages
console.log(details.tables); // Tables d√©tect√©es
```

### EmbeddingService

Service de g√©n√©ration d'embeddings.

```typescript
import { EmbeddingService } from '@/lib/embeddings';

const embedder = new EmbeddingService();

// Embedding simple
const vector = await embedder.generateEmbedding('some text');

// Embeddings multiples
const vectors = await embedder.generateEmbeddings([
  'text 1',
  'text 2',
  'text 3'
]);

// Chunking de texte
const chunks = EmbeddingService.chunkText(
  longText,
  2000,  // chunk size
  200    // overlap
);
```

### SupabaseEmbeddingsService

Service de stockage et recherche.

```typescript
import { SupabaseEmbeddingsService } from '@/lib/supabase-embeddings';

const db = new SupabaseEmbeddingsService();

// Stocker un embedding
await db.storeEmbedding({
  file_path: '/path/to/file.txt',
  file_name: 'file.txt',
  file_type: '.txt',
  content: 'file content',
  embedding: [0.1, 0.2, ...], // vector 1536 dimensions
});

// Rechercher
const results = await db.searchSimilar(
  queryVector,
  0.7,  // threshold
  10    // limit
);

// R√©cup√©rer par chemin
const embedding = await db.getByFilePath('/path/to/file.txt');

// Tout r√©cup√©rer
const all = await db.getAllEmbeddings();
```

## üí° Exemples

### Exemple 1 : Traiter tous les fichiers du projet

```bash
npm run embeddings:process -- . --chunk --skip-existing
```

### Exemple 2 : Recherche avec code personnalis√©

```typescript
import { FileEmbeddingsProcessor } from '@/lib/file-embeddings-processor';

async function searchDocuments(query: string) {
  const processor = new FileEmbeddingsProcessor();
  const results = await processor.search(query, 0.75, 5);

  results.forEach(result => {
    console.log(`üìÑ ${result.file_name}`);
    console.log(`   Similarit√©: ${(result.similarity * 100).toFixed(1)}%`);
    console.log(`   Contenu: ${result.content.substring(0, 100)}...`);
  });
}

await searchDocuments('analyse statistique des jeux de hasard');
```

### Exemple 3 : Traitement personnalis√© avec m√©tadonn√©es

```typescript
import { FileEmbeddingsProcessor } from '@/lib/file-embeddings-processor';
import { SupabaseEmbeddingsService } from '@/lib/supabase-embeddings';

const processor = new FileEmbeddingsProcessor();

// Traiter avec options avanc√©es
const result = await processor.processFile('data/report.pdf', {
  chunkLargeFiles: true,
  chunkSize: 1500,
  skipExisting: false,
  verbose: true,
});

console.log(`‚úÖ Cr√©√© ${result.chunksCreated} chunks`);
```

## üìä Types de fichiers support√©s

### Avec OCR (Azure)
- PDF (`.pdf`)
- Images (`.png`, `.jpg`, `.jpeg`, `.tiff`, `.bmp`)

### Sans OCR (lecture directe)
- Texte (`.txt`)
- CSV (`.csv`)
- Markdown (`.md`)

## üîç Recherche vectorielle

Le syst√®me utilise la similarit√© cosinus pour trouver les documents les plus pertinents.

**Threshold** (seuil de similarit√©) :
- `0.9-1.0` : Tr√®s similaire (presque identique)
- `0.7-0.9` : Similaire (recommand√©)
- `0.5-0.7` : Moyennement similaire
- `< 0.5` : Peu similaire

## üõ†Ô∏è D√©pannage

### Erreur "Azure credentials not found"
V√©rifiez que `.env` contient `AZURE_FORM_RECOGNIZER_ENDPOINT` et `AZURE_FORM_RECOGNIZER_KEY`.

### Erreur "OpenAI API key not found"
V√©rifiez que `.env` contient `OPENAI_API_KEY`.

### Erreur "Supabase credentials not found"
V√©rifiez que `.env` contient `SUPABASE_URL` et `SUPABASE_SERVICE_ROLE_KEY`.

### Pas de r√©sultats de recherche
- Baissez le threshold (essayez `0.5`)
- V√©rifiez que des embeddings existent dans la base
- Reformulez votre requ√™te

## üìù Notes

- Les embeddings utilisent le mod√®le `text-embedding-ada-002` (1536 dimensions)
- Le chunking par d√©faut est de 2000 caract√®res avec 200 de chevauchement
- La recherche vectorielle utilise l'index IVFFlat pour la performance
- Les contenus sont tronqu√©s √† 10000 caract√®res pour le stockage

## üöß Am√©liorations futures

- [ ] Support de plus de types de fichiers (docx, pptx, etc.)
- [ ] Interface web pour la recherche
- [ ] Cache des embeddings pour √©viter les recalculs
- [ ] M√©tadonn√©es enrichies (date de modification, auteur, etc.)
- [ ] Support de mod√®les d'embeddings alternatifs
- [ ] Recherche hybride (vectorielle + full-text)

## üìÑ Licence

Priv√© - Loro Project
